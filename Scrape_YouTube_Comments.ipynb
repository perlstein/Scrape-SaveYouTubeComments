{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Scrape YouTube Comments.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMdsx/RkZ36hWbd9ZcrNGit",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/perlstein/Scrape-SaveYouTubeComments/blob/main/Scrape_YouTube_Comments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ANTTI5Dxr2Z"
      },
      "source": [
        "!apt-get update\n",
        "!apt install chromium-chromedriver\n",
        "%pip install selenium\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
        "import sys\n",
        "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\n",
        "from selenium import webdriver\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.add_argument('--headless')\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "wd = webdriver.Chrome('chromedriver',options=chrome_options)\n",
        "import time\n",
        "from selenium.webdriver import Chrome\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "import pandas as pd\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzof7eVlxt_k"
      },
      "source": [
        "def scrapecomments(url):\n",
        "  print(\"This will take up to an hour, leave window open, and the file will download when finished.\")\n",
        "  tic = time.perf_counter()\n",
        "  wait = WebDriverWait(wd,15)\n",
        "  wd.get(url)\n",
        "  data1=[]\n",
        "  data2=[]\n",
        "  data3=[]\n",
        "  for item in range(200): \n",
        "          wait.until(EC.visibility_of_element_located((By.TAG_NAME,                \"body\"))).send_keys(Keys.END)\n",
        "          time.sleep(15)\n",
        "  for author in wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"#author-text\"))):\n",
        "    if len(data1) == 1000:\n",
        "      break\n",
        "    else:\n",
        "      data1.append(author.text)\n",
        "  for comment in wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"#content-text\"))):\n",
        "          data2.append(comment.text)\n",
        "  for likes in wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"#vote-count-middle\"))):\n",
        "          data3.append(likes.text)\n",
        "\n",
        "  def merge(list1, list2, list3):\n",
        "    merged_list = [(list1[i], list2[i], list3[i]) for i in range(0, len(list1))] \n",
        "    return merged_list\n",
        "  \n",
        "  alldata = merge(data1,data2,data3)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
        "  comments = pd.DataFrame(alldata,columns=['user_id','comment','likes'])\n",
        "  comments['rank'] = comments.reset_index().index +1\n",
        "  channel_name = wd.find_element_by_id('channel-name').text\n",
        "  comments['source'] = channel_name\n",
        "  toc = time.perf_counter()\n",
        "  print(f\"Completed scraping {len(data1)} comments in {toc - tic:0.4f} seconds from YouTube {channel_name} channel.\")\n",
        "  df = pd.DataFrame(comments) \n",
        "  \n",
        "  # saving the dataframe \n",
        "  df.to_csv('filename.csv') \n",
        "  files.download('filename.csv')\n",
        "  return comments\n",
        "  \n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "602fbgDtx298"
      },
      "source": [
        "scrapecomments(input(\"YouTube Video URL: \"))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}